import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import os
import matplotlib.pyplot as plt
import random

from get_data import get_data
from mlp import MLP
from train import train_one_epoch
from attack import attack

n_epoch = 200
batch_size = 100
lr = 5e-5

train_loss_list = []

# data preprocess
p_data, a_data = get_data()
x = torch.from_numpy(p_data['traces'].astype(np.float32))
target = torch.from_numpy(p_data['labels'].astype(np.int64))
# target = F.one_hot(target)
train_dataset = TensorDataset(x, target)
train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=0,
                    drop_last=True, shuffle=False)

model = MLP()
optimizer = optim.RMSprop(model.parameters(), lr=lr, alpha=0.9)
loss_func = nn.CrossEntropyLoss()
# loss_func = nn.NLLLoss()
n_batch = x.size(0) // batch_size

# train
# model_path = rf'weights\MLP-opt_RMSprop-lr_{lr}-batch_{batch_size}-epoch_{n_epoch}-1.pth'
model_path = r'weights\MLP-opt_RMSprop-batch_100-epoch_600.pth'
if os.path.isfile(model_path):
    state_dict = torch.load(model_path)
    model.load_state_dict(state_dict)
else:
    for epoch in range(n_epoch):
        train_loss = train_one_epoch(model, optimizer, loss_func, epoch, n_batch, train_loader, n_epoch)
        train_loss_list.append(train_loss)
    torch.save(model.state_dict(), model_path)

# attack
SBox = np.array([
        0x63, 0x7C, 0x77, 0x7B, 0xF2, 0x6B, 0x6F, 0xC5, 0x30, 0x01, 0x67, 0x2B, 0xFE, 0xD7, 0xAB, 0x76,
        0xCA, 0x82, 0xC9, 0x7D, 0xFA, 0x59, 0x47, 0xF0, 0xAD, 0xD4, 0xA2, 0xAF, 0x9C, 0xA4, 0x72, 0xC0,
        0xB7, 0xFD, 0x93, 0x26, 0x36, 0x3F, 0xF7, 0xCC, 0x34, 0xA5, 0xE5, 0xF1, 0x71, 0xD8, 0x31, 0x15,
        0x04, 0xC7, 0x23, 0xC3, 0x18, 0x96, 0x05, 0x9A, 0x07, 0x12, 0x80, 0xE2, 0xEB, 0x27, 0xB2, 0x75,
        0x09, 0x83, 0x2C, 0x1A, 0x1B, 0x6E, 0x5A, 0xA0, 0x52, 0x3B, 0xD6, 0xB3, 0x29, 0xE3, 0x2F, 0x84,
        0x53, 0xD1, 0x00, 0xED, 0x20, 0xFC, 0xB1, 0x5B, 0x6A, 0xCB, 0xBE, 0x39, 0x4A, 0x4C, 0x58, 0xCF,
        0xD0, 0xEF, 0xAA, 0xFB, 0x43, 0x4D, 0x33, 0x85, 0x45, 0xF9, 0x02, 0x7F, 0x50, 0x3C, 0x9F, 0xA8,
        0x51, 0xA3, 0x40, 0x8F, 0x92, 0x9D, 0x38, 0xF5, 0xBC, 0xB6, 0xDA, 0x21, 0x10, 0xFF, 0xF3, 0xD2,
        0xCD, 0x0C, 0x13, 0xEC, 0x5F, 0x97, 0x44, 0x17, 0xC4, 0xA7, 0x7E, 0x3D, 0x64, 0x5D, 0x19, 0x73,
        0x60, 0x81, 0x4F, 0xDC, 0x22, 0x2A, 0x90, 0x88, 0x46, 0xEE, 0xB8, 0x14, 0xDE, 0x5E, 0x0B, 0xDB,
        0xE0, 0x32, 0x3A, 0x0A, 0x49, 0x06, 0x24, 0x5C, 0xC2, 0xD3, 0xAC, 0x62, 0x91, 0x95, 0xE4, 0x79,
        0xE7, 0xC8, 0x37, 0x6D, 0x8D, 0xD5, 0x4E, 0xA9, 0x6C, 0x56, 0xF4, 0xEA, 0x65, 0x7A, 0xAE, 0x08,
        0xBA, 0x78, 0x25, 0x2E, 0x1C, 0xA6, 0xB4, 0xC6, 0xE8, 0xDD, 0x74, 0x1F, 0x4B, 0xBD, 0x8B, 0x8A,
        0x70, 0x3E, 0xB5, 0x66, 0x48, 0x03, 0xF6, 0x0E, 0x61, 0x35, 0x57, 0xB9, 0x86, 0xC1, 0x1D, 0x9E,
        0xE1, 0xF8, 0x98, 0x11, 0x69, 0xD9, 0x8E, 0x94, 0x9B, 0x1E, 0x87, 0xE9, 0xCE, 0x55, 0x28, 0xDF,
        0x8C, 0xA1, 0x89, 0x0D, 0xBF, 0xE6, 0x42, 0x68, 0x41, 0x99, 0x2D, 0x0F, 0xB0, 0x54, 0xBB, 0x16
], dtype=np.uint8)

# n_attack = a_data['traces'].shape[0]
n_attack = 500
y = torch.from_numpy(a_data['traces'].astype(np.float32))
p_y = model(y)
p_y = torch.log_softmax(p_y, dim=1)

it = 1
ge_avg = np.zeros(n_attack // 10)
for i in range(it):
    if i % 10 == 0:
        print(f'it = {i}')
    idx = random.sample(range(10000), n_attack)
    tmp_y = p_y[idx]
    tmp_plain = a_data['plainx'][idx]
    ge, p_keys = attack(tmp_y, tmp_plain)
    ge_avg += ge

ge_avg /= it
plt.plot(range(0, n_attack, 10), ge_avg)
# plt.plot(range(256), p_keys)
plt.show()



np.save(rf'ret\mlp-GE-opt_RMSprop-lr_{lr}-batch_{batch_size}-epoch_{n_epoch}.npy', ge_avg)



pass